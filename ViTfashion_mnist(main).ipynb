{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0M1sSidKZTOI+bPHYVDyG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sauleh-repo/Transformers/blob/main/ViTfashion_mnist(main).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "dmg_ApWDhpIL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0IQmqgC_Kpe2"
      },
      "outputs": [],
      "source": [
        "class ClassToken(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.cls = self.add_weight(\n",
        "            name=\"cls\",\n",
        "            shape=(1, 1, input_shape[-1]),\n",
        "            initializer=\"zeros\",\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        cls = tf.tile(self.cls, [batch_size, 1, 1])\n",
        "        x = tf.concat([cls, x], axis=1)\n",
        "        return x\n",
        "\n",
        "def mlp(x, cf):\n",
        "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    x = Dense(cf[\"hidden_dim\"])(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    return x\n",
        "\n",
        "def transformer_encoder(x, cf):\n",
        "    skip_1 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = MultiHeadAttention(\n",
        "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
        "    )(x, x)\n",
        "    x = Add()([x, skip_1])\n",
        "\n",
        "    skip_2 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = mlp(x, cf)\n",
        "    x = Add()([x, skip_2])\n",
        "\n",
        "    return x\n",
        "\n",
        "def ViT(cf):\n",
        "\n",
        "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)\n",
        "\n",
        "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
        "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions)\n",
        "    embed = patch_embed + pos_embed\n",
        "\n",
        "\n",
        "    x = ClassToken()(embed)\n",
        "\n",
        "    for _ in range(cf[\"num_layers\"]):\n",
        "        x = transformer_encoder(x, cf)\n",
        "\n",
        "    x = LayerNormalization()(x)\n",
        "    x = x[:, 0, :]\n",
        "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image, patch_size):\n",
        "    image = tf.reshape(image, (28, 28, 1))\n",
        "    image = tf.image.resize(image, (28, 28))\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    image = tf.cast(image, tf.float32) / 255.05\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=image,\n",
        "        sizes=[1, patch_size, patch_size, 1],\n",
        "        strides=[1, patch_size, patch_size, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "    patches = tf.reshape(patches, (patches.shape[0], -1, patches.shape[-1]))\n",
        "    return patches\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "    subset_size = 5000\n",
        "    x_train, y_train = x_train[:subset_size], y_train[:subset_size]\n",
        "    x_test, y_test = x_test[:1000], y_test[:1000]\n",
        "\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    patch_size = 14\n",
        "    num_patches = (28 // patch_size) ** 2\n",
        "\n",
        "    x_train = tf.image.extract_patches(\n",
        "        images=tf.expand_dims(x_train, axis=-1),\n",
        "        sizes=[1, patch_size, patch_size, 1],\n",
        "        strides=[1, patch_size, patch_size, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "    x_train = tf.reshape(x_train, (x_train.shape[0], num_patches, -1))\n",
        "\n",
        "    x_test = tf.image.extract_patches(\n",
        "        images=tf.expand_dims(x_test, axis=-1),\n",
        "        sizes=[1, patch_size, patch_size, 1],\n",
        "        strides=[1, patch_size, patch_size, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "    x_test = tf.reshape(x_test, (x_test.shape[0], num_patches, -1))\n",
        "\n",
        "    config = {\n",
        "        \"num_layers\": 4,\n",
        "        \"hidden_dim\": 128,\n",
        "        \"mlp_dim\": 256,\n",
        "        \"num_heads\": 4,\n",
        "        \"dropout_rate\": 0.1,\n",
        "        \"num_patches\": num_patches,\n",
        "        \"patch_size\": patch_size,\n",
        "        \"num_channels\": 1,\n",
        "        \"num_classes\": 10\n",
        "    }\n",
        "\n",
        "    model = ViT(config)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "    model.save(\"vit_fashion_mnist_cls.h5\")\n",
        "\n",
        "    print(\"Model trained. Ready to classify a new image.\")\n",
        "\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = tf.argmax(y_pred, axis=1).numpy()\n",
        "\n",
        "    print(\"Evaluation Metrics on Test Set:\")\n",
        "    print(classification_report(y_test, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb9GyOObhwxl",
        "outputId": "5ebb6c8a-ef0e-490f-d178-df813a656773"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 84ms/step - accuracy: 0.4804 - loss: 1.5374 - val_accuracy: 0.6440 - val_loss: 0.8814\n",
            "Epoch 2/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7485 - loss: 0.6811 - val_accuracy: 0.7190 - val_loss: 0.8257\n",
            "Epoch 3/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7789 - loss: 0.6036 - val_accuracy: 0.7890 - val_loss: 0.5755\n",
            "Epoch 4/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7922 - loss: 0.5604 - val_accuracy: 0.7850 - val_loss: 0.6123\n",
            "Epoch 5/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8045 - loss: 0.5377 - val_accuracy: 0.8120 - val_loss: 0.5362\n",
            "Epoch 6/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8051 - loss: 0.5116 - val_accuracy: 0.8050 - val_loss: 0.5386\n",
            "Epoch 7/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8377 - loss: 0.4528 - val_accuracy: 0.7710 - val_loss: 0.6277\n",
            "Epoch 8/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8262 - loss: 0.4621 - val_accuracy: 0.7700 - val_loss: 0.6502\n",
            "Epoch 9/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8204 - loss: 0.4824 - val_accuracy: 0.8160 - val_loss: 0.5147\n",
            "Epoch 10/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8463 - loss: 0.4177 - val_accuracy: 0.7850 - val_loss: 0.5703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained. Ready to classify a new image.\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step\n",
            "Evaluation Metrics on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.53      0.64       107\n",
            "           1       0.96      0.93      0.95       105\n",
            "           2       0.81      0.63      0.71       111\n",
            "           3       0.80      0.78      0.79        93\n",
            "           4       0.77      0.71      0.74       115\n",
            "           5       0.84      0.93      0.88        87\n",
            "           6       0.40      0.73      0.52        97\n",
            "           7       0.93      0.82      0.87        95\n",
            "           8       0.97      0.92      0.94        95\n",
            "           9       0.93      0.93      0.93        95\n",
            "\n",
            "    accuracy                           0.79      1000\n",
            "   macro avg       0.82      0.79      0.80      1000\n",
            "weighted avg       0.82      0.79      0.79      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    new_image = x_test[146]\n",
        "\n",
        "    prediction = model.predict(tf.expand_dims(new_image,axis=0))\n",
        "    predicted_class = tf.argmax(prediction, axis=1).numpy()[0]\n",
        "    print(f\"Predicted Class: {predicted_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fc0ng27L7Zt",
        "outputId": "a63ff0be-a26b-427c-d133-7fc664714a7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Predicted Class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the FashionMNIST dataset\n",
        "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Print the output values with their indices\n",
        "#for i in range(200):\n",
        " # print(f\"Index: {i}, Output Value (Label): {y_train[i]}\")\n",
        "\n",
        "# You can do the same for the test set if needed:\n",
        "for i in range(200):\n",
        "   print(f\"Index: {i}, Output Value (Label): {y_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHZHuHmAlC-_",
        "outputId": "caae3206-cb02-4583-eb5d-27bfe35d8756"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 0, Output Value (Label): 9\n",
            "Index: 1, Output Value (Label): 2\n",
            "Index: 2, Output Value (Label): 1\n",
            "Index: 3, Output Value (Label): 1\n",
            "Index: 4, Output Value (Label): 6\n",
            "Index: 5, Output Value (Label): 1\n",
            "Index: 6, Output Value (Label): 4\n",
            "Index: 7, Output Value (Label): 6\n",
            "Index: 8, Output Value (Label): 5\n",
            "Index: 9, Output Value (Label): 7\n",
            "Index: 10, Output Value (Label): 4\n",
            "Index: 11, Output Value (Label): 5\n",
            "Index: 12, Output Value (Label): 7\n",
            "Index: 13, Output Value (Label): 3\n",
            "Index: 14, Output Value (Label): 4\n",
            "Index: 15, Output Value (Label): 1\n",
            "Index: 16, Output Value (Label): 2\n",
            "Index: 17, Output Value (Label): 4\n",
            "Index: 18, Output Value (Label): 8\n",
            "Index: 19, Output Value (Label): 0\n",
            "Index: 20, Output Value (Label): 2\n",
            "Index: 21, Output Value (Label): 5\n",
            "Index: 22, Output Value (Label): 7\n",
            "Index: 23, Output Value (Label): 9\n",
            "Index: 24, Output Value (Label): 1\n",
            "Index: 25, Output Value (Label): 4\n",
            "Index: 26, Output Value (Label): 6\n",
            "Index: 27, Output Value (Label): 0\n",
            "Index: 28, Output Value (Label): 9\n",
            "Index: 29, Output Value (Label): 3\n",
            "Index: 30, Output Value (Label): 8\n",
            "Index: 31, Output Value (Label): 8\n",
            "Index: 32, Output Value (Label): 3\n",
            "Index: 33, Output Value (Label): 3\n",
            "Index: 34, Output Value (Label): 8\n",
            "Index: 35, Output Value (Label): 0\n",
            "Index: 36, Output Value (Label): 7\n",
            "Index: 37, Output Value (Label): 5\n",
            "Index: 38, Output Value (Label): 7\n",
            "Index: 39, Output Value (Label): 9\n",
            "Index: 40, Output Value (Label): 6\n",
            "Index: 41, Output Value (Label): 1\n",
            "Index: 42, Output Value (Label): 3\n",
            "Index: 43, Output Value (Label): 7\n",
            "Index: 44, Output Value (Label): 6\n",
            "Index: 45, Output Value (Label): 7\n",
            "Index: 46, Output Value (Label): 2\n",
            "Index: 47, Output Value (Label): 1\n",
            "Index: 48, Output Value (Label): 2\n",
            "Index: 49, Output Value (Label): 2\n",
            "Index: 50, Output Value (Label): 4\n",
            "Index: 51, Output Value (Label): 4\n",
            "Index: 52, Output Value (Label): 5\n",
            "Index: 53, Output Value (Label): 8\n",
            "Index: 54, Output Value (Label): 2\n",
            "Index: 55, Output Value (Label): 2\n",
            "Index: 56, Output Value (Label): 8\n",
            "Index: 57, Output Value (Label): 4\n",
            "Index: 58, Output Value (Label): 8\n",
            "Index: 59, Output Value (Label): 0\n",
            "Index: 60, Output Value (Label): 7\n",
            "Index: 61, Output Value (Label): 7\n",
            "Index: 62, Output Value (Label): 8\n",
            "Index: 63, Output Value (Label): 5\n",
            "Index: 64, Output Value (Label): 1\n",
            "Index: 65, Output Value (Label): 1\n",
            "Index: 66, Output Value (Label): 2\n",
            "Index: 67, Output Value (Label): 3\n",
            "Index: 68, Output Value (Label): 9\n",
            "Index: 69, Output Value (Label): 8\n",
            "Index: 70, Output Value (Label): 7\n",
            "Index: 71, Output Value (Label): 0\n",
            "Index: 72, Output Value (Label): 2\n",
            "Index: 73, Output Value (Label): 6\n",
            "Index: 74, Output Value (Label): 2\n",
            "Index: 75, Output Value (Label): 3\n",
            "Index: 76, Output Value (Label): 1\n",
            "Index: 77, Output Value (Label): 2\n",
            "Index: 78, Output Value (Label): 8\n",
            "Index: 79, Output Value (Label): 4\n",
            "Index: 80, Output Value (Label): 1\n",
            "Index: 81, Output Value (Label): 8\n",
            "Index: 82, Output Value (Label): 5\n",
            "Index: 83, Output Value (Label): 9\n",
            "Index: 84, Output Value (Label): 5\n",
            "Index: 85, Output Value (Label): 0\n",
            "Index: 86, Output Value (Label): 3\n",
            "Index: 87, Output Value (Label): 2\n",
            "Index: 88, Output Value (Label): 0\n",
            "Index: 89, Output Value (Label): 6\n",
            "Index: 90, Output Value (Label): 5\n",
            "Index: 91, Output Value (Label): 3\n",
            "Index: 92, Output Value (Label): 6\n",
            "Index: 93, Output Value (Label): 7\n",
            "Index: 94, Output Value (Label): 1\n",
            "Index: 95, Output Value (Label): 8\n",
            "Index: 96, Output Value (Label): 0\n",
            "Index: 97, Output Value (Label): 1\n",
            "Index: 98, Output Value (Label): 4\n",
            "Index: 99, Output Value (Label): 2\n",
            "Index: 100, Output Value (Label): 3\n",
            "Index: 101, Output Value (Label): 6\n",
            "Index: 102, Output Value (Label): 7\n",
            "Index: 103, Output Value (Label): 2\n",
            "Index: 104, Output Value (Label): 7\n",
            "Index: 105, Output Value (Label): 8\n",
            "Index: 106, Output Value (Label): 5\n",
            "Index: 107, Output Value (Label): 9\n",
            "Index: 108, Output Value (Label): 9\n",
            "Index: 109, Output Value (Label): 4\n",
            "Index: 110, Output Value (Label): 2\n",
            "Index: 111, Output Value (Label): 5\n",
            "Index: 112, Output Value (Label): 7\n",
            "Index: 113, Output Value (Label): 0\n",
            "Index: 114, Output Value (Label): 5\n",
            "Index: 115, Output Value (Label): 2\n",
            "Index: 116, Output Value (Label): 8\n",
            "Index: 117, Output Value (Label): 6\n",
            "Index: 118, Output Value (Label): 7\n",
            "Index: 119, Output Value (Label): 8\n",
            "Index: 120, Output Value (Label): 0\n",
            "Index: 121, Output Value (Label): 0\n",
            "Index: 122, Output Value (Label): 9\n",
            "Index: 123, Output Value (Label): 9\n",
            "Index: 124, Output Value (Label): 3\n",
            "Index: 125, Output Value (Label): 0\n",
            "Index: 126, Output Value (Label): 8\n",
            "Index: 127, Output Value (Label): 4\n",
            "Index: 128, Output Value (Label): 1\n",
            "Index: 129, Output Value (Label): 5\n",
            "Index: 130, Output Value (Label): 4\n",
            "Index: 131, Output Value (Label): 1\n",
            "Index: 132, Output Value (Label): 9\n",
            "Index: 133, Output Value (Label): 1\n",
            "Index: 134, Output Value (Label): 8\n",
            "Index: 135, Output Value (Label): 6\n",
            "Index: 136, Output Value (Label): 2\n",
            "Index: 137, Output Value (Label): 1\n",
            "Index: 138, Output Value (Label): 2\n",
            "Index: 139, Output Value (Label): 5\n",
            "Index: 140, Output Value (Label): 1\n",
            "Index: 141, Output Value (Label): 0\n",
            "Index: 142, Output Value (Label): 0\n",
            "Index: 143, Output Value (Label): 0\n",
            "Index: 144, Output Value (Label): 1\n",
            "Index: 145, Output Value (Label): 6\n",
            "Index: 146, Output Value (Label): 1\n",
            "Index: 147, Output Value (Label): 6\n",
            "Index: 148, Output Value (Label): 2\n",
            "Index: 149, Output Value (Label): 2\n",
            "Index: 150, Output Value (Label): 4\n",
            "Index: 151, Output Value (Label): 4\n",
            "Index: 152, Output Value (Label): 1\n",
            "Index: 153, Output Value (Label): 4\n",
            "Index: 154, Output Value (Label): 5\n",
            "Index: 155, Output Value (Label): 0\n",
            "Index: 156, Output Value (Label): 4\n",
            "Index: 157, Output Value (Label): 7\n",
            "Index: 158, Output Value (Label): 9\n",
            "Index: 159, Output Value (Label): 3\n",
            "Index: 160, Output Value (Label): 7\n",
            "Index: 161, Output Value (Label): 2\n",
            "Index: 162, Output Value (Label): 3\n",
            "Index: 163, Output Value (Label): 9\n",
            "Index: 164, Output Value (Label): 0\n",
            "Index: 165, Output Value (Label): 9\n",
            "Index: 166, Output Value (Label): 4\n",
            "Index: 167, Output Value (Label): 7\n",
            "Index: 168, Output Value (Label): 4\n",
            "Index: 169, Output Value (Label): 2\n",
            "Index: 170, Output Value (Label): 0\n",
            "Index: 171, Output Value (Label): 5\n",
            "Index: 172, Output Value (Label): 2\n",
            "Index: 173, Output Value (Label): 1\n",
            "Index: 174, Output Value (Label): 2\n",
            "Index: 175, Output Value (Label): 1\n",
            "Index: 176, Output Value (Label): 3\n",
            "Index: 177, Output Value (Label): 0\n",
            "Index: 178, Output Value (Label): 9\n",
            "Index: 179, Output Value (Label): 1\n",
            "Index: 180, Output Value (Label): 0\n",
            "Index: 181, Output Value (Label): 9\n",
            "Index: 182, Output Value (Label): 3\n",
            "Index: 183, Output Value (Label): 6\n",
            "Index: 184, Output Value (Label): 7\n",
            "Index: 185, Output Value (Label): 9\n",
            "Index: 186, Output Value (Label): 9\n",
            "Index: 187, Output Value (Label): 4\n",
            "Index: 188, Output Value (Label): 4\n",
            "Index: 189, Output Value (Label): 7\n",
            "Index: 190, Output Value (Label): 1\n",
            "Index: 191, Output Value (Label): 2\n",
            "Index: 192, Output Value (Label): 1\n",
            "Index: 193, Output Value (Label): 6\n",
            "Index: 194, Output Value (Label): 3\n",
            "Index: 195, Output Value (Label): 2\n",
            "Index: 196, Output Value (Label): 8\n",
            "Index: 197, Output Value (Label): 3\n",
            "Index: 198, Output Value (Label): 6\n",
            "Index: 199, Output Value (Label): 1\n"
          ]
        }
      ]
    }
  ]
}